import os
import numpy as np
from tqdm import tqdm
from dotenv import load_dotenv
from pymilvus import (
    connections,
    utility,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
)

# Load environment variables from .env file
load_dotenv()

# ==========================================
# 1. CONFIGURATION
# ==========================================
CONFIG = {
    # Milvus Connection Settings
    # Prioritize environment variables, fallback to localhost default
    'milvus_uri': os.getenv('MILVUS_URI', 'http://localhost:19530'),
    'milvus_token': os.getenv('MILVUS_TOKEN', ''),  # Leave empty for localhost
    
    'collection_name': 'movies_multimodal',
    
    # Paths to .npy files generated by generate_embeddings.py
    'ids_path': './ml-20m-psm/data/embeddings/movie_ids.npy',
    'text_emb_path': './ml-20m-psm/data/embeddings/text_feat.npy',
    'img_emb_path': './ml-20m-psm/data/embeddings/image_feat.npy',
    
    # Vector Dimensions
    # Must match the output of the models used in generation
    'dim_visual': 512,  # OpenAI CLIP ViT-B/32 (Projected)
    'dim_text': 768,    # Sentence-BERT all-mpnet-base-v2
    
    # Batch size for insertion
    # Milvus has a 64MB gRPC limit per request. 
    # 1000 items * (512+768 floats) is safe.
    'insert_batch_size': 1000 
}

def connect_milvus():
    """
    Connects to the Milvus server using URI and Token.
    Supports both Local Docker and Zilliz Cloud.
    """
    print(f"[INFO] Connecting to Milvus at {CONFIG['milvus_uri']}...")
    try:
        # If token is provided (Cloud), use it. Otherwise, connect anonymously (Local)
        if CONFIG['milvus_token']:
            connections.connect("default", uri=CONFIG['milvus_uri'], token=CONFIG['milvus_token'])
        else:
            connections.connect("default", uri=CONFIG['milvus_uri'])
            
        print("[INFO] Connected to Milvus successfully.")
    except Exception as e:
        print(f"[ERROR] Failed to connect to Milvus: {e}")
        exit(1)

def create_collection():
    """
    Defines the Schema and creates the Collection in Milvus.
    Drops the existing collection if it exists to ensure a clean state.
    """
    col_name = CONFIG['collection_name']
    
    # Check if collection exists and drop it
    if utility.has_collection(col_name):
        print(f"[WARN] Collection '{col_name}' already exists. Dropping it...")
        utility.drop_collection(col_name)
    
    print(f"[INFO] Creating collection '{col_name}'...")
    
    # Define Fields
    fields = [
        # Primary Key: Movie ID (User-provided int64)
        FieldSchema(name="movie_id", dtype=DataType.INT64, is_primary=True, auto_id=False),
        
        # Visual Embedding Vector
        FieldSchema(name="visual_emb", dtype=DataType.FLOAT_VECTOR, dim=CONFIG['dim_visual']),
        
        # Textual Embedding Vector
        FieldSchema(name="text_emb", dtype=DataType.FLOAT_VECTOR, dim=CONFIG['dim_text'])
    ]
    
    # Define Schema
    schema = CollectionSchema(fields, "Multimodal Embeddings for Movie Recommendation")
    
    # Create Collection
    # For Zilliz Cloud, you might want to set consistency_level="Strong" if immediate read is needed
    collection = Collection(col_name, schema)
    
    print("[INFO] Collection created successfully.")
    return collection

def insert_data(collection):
    """
    Loads data from .npy files and inserts it into the Milvus collection in batches.
    """
    print("\n[INFO] Loading .npy files from disk...")
    
    if not os.path.exists(CONFIG['ids_path']):
        print(f"[ERROR] File not found: {CONFIG['ids_path']}")
        return

    # Load data using numpy
    ids = np.load(CONFIG['ids_path'])
    text_vecs = np.load(CONFIG['text_emb_path'])
    img_vecs = np.load(CONFIG['img_emb_path'])
    
    num_entities = len(ids)
    print(f" -> Loaded {num_entities} items.")
    print(f" -> Text Embeddings Shape: {text_vecs.shape}")
    print(f" -> Image Embeddings Shape: {img_vecs.shape}")
    
    # Verify data consistency
    if len(text_vecs) != num_entities or len(img_vecs) != num_entities:
        print("[ERROR] Mismatch in data lengths (IDs vs Vectors).")
        return

    # --- BATCH INSERT LOGIC ---
    batch_size = CONFIG['insert_batch_size']
    print(f"[INFO] Inserting into Milvus in batches of {batch_size}...")
    
    # Iterate through data in chunks
    for i in tqdm(range(0, num_entities, batch_size), desc="Inserting"):
        end_idx = min(i + batch_size, num_entities)
        
        # Slice data for current batch
        # Convert IDs to list (required by pymilvus)
        batch_ids = ids[i:end_idx].tolist()
        batch_img = img_vecs[i:end_idx]
        batch_text = text_vecs[i:end_idx]
        
        # Prepare data list: [PK_Column, Vector_Column_1, Vector_Column_2]
        batch_data = [
            batch_ids,
            batch_img,
            batch_text
        ]
        
        # Insert current batch
        collection.insert(batch_data)
    
    # Flush to ensure data is persisted to disk/cloud storage
    print("[INFO] Flushing data...")
    collection.flush()
    print(f"[SUCCESS] Insertion complete. Total entities in DB: {collection.num_entities}")

def create_index(collection):
    """
    Builds indexes for vector fields to enable fast similarity search.
    """
    print("\n[INFO] Building Indexes...")
    
    # Index configuration
    # Metric Type: IP (Inner Product). Since vectors are normalized, IP == Cosine Similarity.
    # Index Type: AUTOINDEX (Best for Cloud) or IVF_FLAT (Standard for Local)
    # Using IVF_FLAT as a safe default for both.
    index_params = {
        "metric_type": "IP",
        "index_type": "IVF_FLAT", 
        "params": {"nlist": 128}  # Number of cluster buckets
    }
    
    # Create index for Visual Embedding column
    print(" -> Indexing 'visual_emb'...")
    collection.create_index(field_name="visual_emb", index_params=index_params)
    
    # Create index for Textual Embedding column
    print(" -> Indexing 'text_emb'...")
    collection.create_index(field_name="text_emb", index_params=index_params)
    
    print("[SUCCESS] Indexes built successfully.")
    
    # Load collection into memory for searching
    collection.load()
    print("[INFO] Collection loaded to memory. Ready for use.")

# ==========================================
# MAIN EXECUTION
# ==========================================
def main():
    # Step 1: Connect
    connect_milvus()
    
    # Step 2: Create Collection
    collection = create_collection()
    
    # Step 3: Insert Data
    insert_data(collection)
    
    # Step 4: Build Index
    create_index(collection)
    
    print("\n=== MILVUS SETUP COMPLETED ===")

if __name__ == "__main__":
    main()